import { useCallback, useState, useRef, useEffect } from 'react';
import { Live2DModel } from 'pixi-live2d-display';
import { parseEmotionMessage } from '@/lib/utils';

interface SpeechAndAnimationOptions {
  model: Live2DModel | null;
  voice?: string;
  rate?: number;
  pitch?: number;
}

export const useSpeechAndAnimation = (model: Live2DModel | null) => {
  const [isSpeaking, setIsSpeaking] = useState(false);
  const utteranceRef = useRef<SpeechSynthesisUtterance | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyzerRef = useRef<AnalyserNode | null>(null);
  const volumeDataRef = useRef<Float32Array | null>(null);
  const intervalRef = useRef<NodeJS.Timeout | null>(null);

  // í›… ìƒì„± ë¡œê·¸ ì œê±° (ì„±ëŠ¥ ê°œì„ )

  // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ì™€ ë¶„ì„ê¸° ì´ˆê¸°í™”
  const initializeAudioAnalysis = useCallback(() => {
    if (audioContextRef.current) return;

    try {
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
      analyzerRef.current = audioContextRef.current.createAnalyser();
      analyzerRef.current.fftSize = 256;
      volumeDataRef.current = new Float32Array(analyzerRef.current.frequencyBinCount);

      console.log('ğŸµ ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ');
    } catch (error) {
      console.error('ğŸµ ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
    }
  }, []);

  // ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ì—ë„ˆì§€ ê³„ì‚° í—¬í¼ í•¨ìˆ˜
  const calculateFrequencyEnergy = useCallback((frequencyData: Float32Array, startBin: number, endBin: number, totalBins: number): number => {
    const actualEnd = Math.min(endBin, totalBins);
    const actualStart = Math.min(startBin, actualEnd);

    if (actualStart >= actualEnd) return 0;

    let energy = 0;
    for (let i = actualStart; i < actualEnd; i++) {
      // dBë¥¼ ë¦¬ë‹ˆì–´ ê°’ìœ¼ë¡œ ë³€í™˜: 10^(dB/20)
      const linearValue = Math.pow(10, frequencyData[i] / 20);
      energy += linearValue;
    }

    return energy / (actualEnd - actualStart); // í‰ê· ê°’ ë°˜í™˜
  }, []);

  // ì‹¤ì‹œê°„ ì£¼íŒŒìˆ˜ ê¸°ë°˜ ë¹„ì„¸ì„ ì„ íƒ í•¨ìˆ˜
  const selectVisemeFromFrequency = useCallback((frequencyData: Float32Array): { param: string; value: number; name: string } => {
    // ì£¼íŒŒìˆ˜ ë°ì´í„°ê°€ ìœ íš¨í•œì§€ í™•ì¸
    if (!frequencyData || frequencyData.length === 0) {
      return { param: 'ParamA', value: 0, name: 'ë¬´ìŒ(ì£¼íŒŒìˆ˜ì—†ìŒ)' };
    }

    // ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ë¡œ ì—ë„ˆì§€ ê³„ì‚° (dBë¥¼ ë¦¬ë‹ˆì–´ë¡œ ë³€í™˜)
    const binCount = Math.min(frequencyData.length, 128); // ìµœëŒ€ 128ê°œ ë¹ˆë§Œ ì‚¬ìš©
    const lowFreq = calculateFrequencyEnergy(frequencyData, 0, 8, binCount);      // ì €ìŒ (50-200Hz)
    const midLowFreq = calculateFrequencyEnergy(frequencyData, 8, 24, binCount);  // ì¤‘ì €ìŒ (200-600Hz) 
    const midFreq = calculateFrequencyEnergy(frequencyData, 24, 48, binCount);    // ì¤‘ìŒ (600-1200Hz)
    const highFreq = calculateFrequencyEnergy(frequencyData, 48, 80, binCount);   // ê³ ìŒ (1200-2000Hz)
    const veryHighFreq = calculateFrequencyEnergy(frequencyData, 80, binCount, binCount); // ì´ˆê³ ìŒ (2000Hz+)

    // ì „ì²´ ì—ë„ˆì§€ ê³„ì‚°
    const totalEnergy = lowFreq + midLowFreq + midFreq + highFreq + veryHighFreq;
    const volume = Math.min(1, Math.max(0, totalEnergy * 10)); // ë³¼ë¥¨ ë¯¼ê°ë„ ë”ìš± ì¦ê°€ (5 â†’ 10)

    // ë””ë²„ê¹… ì •ë³´ (1% í™•ë¥ ë¡œ ì¶œë ¥ - ì„±ëŠ¥ ê°œì„ )
    if (Math.random() < 0.01 && volume > 0.005) { // ë¬´ìŒ ìƒíƒœì—ì„œëŠ” ë¡œê·¸ ì•ˆí•¨ (ì„ê³„ê°’ ë§ì¶¤)
      console.log('ğŸ”Š ì£¼íŒŒìˆ˜ ë¶„ì„:', {
        ì´ì—ë„ˆì§€: totalEnergy.toFixed(4),
        ë³¼ë¥¨: volume.toFixed(3),
        ì €ìŒ: lowFreq.toFixed(3),
        ì¤‘ì €ìŒ: midLowFreq.toFixed(3),
        ì¤‘ìŒ: midFreq.toFixed(3),
        ê³ ìŒ: highFreq.toFixed(3),
        ì´ˆê³ ìŒ: veryHighFreq.toFixed(3)
      });
    }

    // ìµœì†Œ ë³¼ë¥¨ ì„ê³„ê°’ í™•ì¸ (ë¡œê·¸ ì—†ì´) - ë” ë¯¼ê°í•˜ê²Œ ì¡°ì •
    if (volume < 0.005) { // 0.02ì—ì„œ 0.005ë¡œ ëŒ€í­ ë‚®ì¶¤
      return { param: 'ParamA', value: 0, name: 'ë¬´ìŒ(ì„ê³„ê°’ë¯¸ë§Œ)' };
    }

    // ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ê°•ë„ë¥¼ ì •ê·œí™”
    if (totalEnergy < 0.001) {
      return { param: 'ParamA', value: volume, name: 'ã…(ì•„)-ê¸°ë³¸' };
    }

    const lowRatio = lowFreq / totalEnergy;
    const midLowRatio = midLowFreq / totalEnergy;
    const midRatio = midFreq / totalEnergy;
    const highRatio = highFreq / totalEnergy;
    const veryHighRatio = veryHighFreq / totalEnergy;

    // ë¹„ì„¸ì„ ì„ íƒ ë¡œì§ (í•œêµ­ì–´ ìŒì„±í•™ ê¸°ë°˜)
    let selectedParam = 'ParamA';
    let selectedName = 'ã…(ì•„)';
    let confidence = 0;

    // ê° ë¹„ì„¸ì„ë³„ ì ìˆ˜ ê³„ì‚° (ë” ë¯¼ê°í•˜ê²Œ ì¡°ì •)
    const visemeScores = {
      ParamU: lowRatio * 3.0 + midLowRatio * 1.0, // ã…œ, ã…— - ì €ìŒ ê°•ì¡° (ë” ë¯¼ê°)
      ParamO: lowRatio * 2.0 + midLowRatio * 2.5 + midRatio * 0.8, // ã…— - ì €ìŒ+ì¤‘ì €ìŒ (ë” ë¯¼ê°)
      ParamE: midRatio * 3.0 + highRatio * 2.0, // ã…”, ã… - ì¤‘ìŒ+ê³ ìŒ (ë” ë¯¼ê°)
      ParamI: highRatio * 3.5 + veryHighRatio * 2.5, // ã…£ - ê³ ìŒ+ì´ˆê³ ìŒ (ë” ë¯¼ê°)
      ParamA: midLowRatio * 1.5 + midRatio * 1.5 + lowRatio * 0.5 // ã… - ë²”ìš©ì„± ì¦ê°€
    };

    // ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë¹„ì„¸ì„ ì„ íƒ
    const maxScore = Math.max(...Object.values(visemeScores));
    if (maxScore > 0.1) { // ì‹ ë¢°ë„ ì„ê³„ê°’ ë‚®ì¶¤ (0.3 â†’ 0.1)
      for (const [param, score] of Object.entries(visemeScores)) {
        if (score === maxScore) {
          selectedParam = param;
          confidence = score;

          switch (param) {
            case 'ParamU': selectedName = 'ã…œ(ìš°)'; break;
            case 'ParamO': selectedName = 'ã…—(ì˜¤)'; break;
            case 'ParamE': selectedName = 'ã…”(ì—)'; break;
            case 'ParamI': selectedName = 'ã…£(ì´)'; break;
            default: selectedName = 'ã…(ì•„)'; break;
          }
          break;
        }
      }
    }

    return {
      param: selectedParam,
      value: Math.min(1, volume * (1 + confidence)), // ì‹ ë¢°ë„ë¡œ ë³¼ë¥¨ ë³´ì •
      name: selectedName
    };
  }, [calculateFrequencyEnergy]); // calculateFrequencyEnergy í•¨ìˆ˜ë¥¼ ì˜ì¡´ì„±ì— ì¶”ê°€

  // mao ëª¨ë¸ì˜ ì—¬ëŸ¬ ë¹„ì„¸ì„ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì ìš©í•˜ëŠ” í•¨ìˆ˜
  const applyRealtimeViseme = useCallback((selectedViseme: { param: string; value: number; name: string }) => {
    if (!model) return;

    try {
      const internalModel = (model as any).internalModel;
      if (!internalModel?.coreModel) return;

      const coreModel = internalModel.coreModel;

      // ëª¨ë“  ë¹„ì„¸ì„ íŒŒë¼ë¯¸í„°ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™” (ParamMouthOpenY í¬í•¨)
      const allVisemes = ['ParamA', 'ParamO', 'ParamU', 'ParamE', 'ParamI', 'ParamMouthOpenY'];

      // ParamMouthOpenY ì¸ë±ìŠ¤ ì°¾ê¸° (ë¯¸ë¦¬ ì°¾ì•„ì„œ ìµœì í™”)
      let mouthOpenYIndex = -1;
      try {
        if (coreModel.getParameterIndex) {
          mouthOpenYIndex = coreModel.getParameterIndex('ParamMouthOpenY');
        }
      } catch (e) { }

      for (const viseme of allVisemes) {
        try {
          let paramIndex = -1;
          if (coreModel.getParameterIndex) {
            paramIndex = coreModel.getParameterIndex(viseme);
          }

          if (paramIndex >= 0) {
            let value = 0;

            // ì„ íƒëœ ë¹„ì„¸ì„ì´ë©´ ê°’ ì„¤ì •
            if (viseme === selectedViseme.param) {
              value = selectedViseme.value;
            }
            // ParamMouthOpenYëŠ” ì„ íƒëœ ë¹„ì„¸ì„ì´ ëª¨ìŒ(ParamA ë“±)ì¼ ë•Œë„ ê°™ì´ ì›€ì§ì´ë„ë¡ ì„¤ì •
            else if (viseme === 'ParamMouthOpenY' && selectedViseme.value > 0.01) {
              // ëª¨ìŒ íŒŒë¼ë¯¸í„°ê°€ í™œì„±í™”ë˜ë©´ ParamMouthOpenYë„ ê°™ì´ ì—´ì–´ì¤Œ (mao ëª¨ë¸ ë“± í˜¸í™˜ì„±)
              value = selectedViseme.value;
            }

            coreModel.setParameterValueByIndex(paramIndex, value);
          }
        } catch (error) {
          // ê°œë³„ íŒŒë¼ë¯¸í„° ì„¤ì • ì‹¤íŒ¨ ë¬´ì‹œ
        }
      }

      // ëª¨ë¸ ì—…ë°ì´íŠ¸
      if (coreModel.update) coreModel.update();
      if (model.update) model.update(0.016);

    } catch (error) {
      console.warn('ì‹¤ì‹œê°„ ë¹„ì„¸ì„ ì ìš© ì˜¤ë¥˜:', error);
    }
  }, [model]);

  // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë³¼ë¥¨ ê¸°ë°˜ ì… ì• ë‹ˆë©”ì´ì…˜
  const animateMouthWithVolume = useCallback((isMoving: boolean) => {
    console.log('ğŸ­ ë³¼ë¥¨ ê¸°ë°˜ animateMouth í˜¸ì¶œ:', {
      isMoving,
      modelExists: !!model,
      modelType: model?.constructor?.name,
      hasAudioContext: !!audioContextRef.current,
      hasAnalyzer: !!analyzerRef.current
    });

    if (!model) {
      console.warn('ğŸ­ ëª¨ë¸ì´ ì—†ì–´ì„œ ì… ì• ë‹ˆë©”ì´ì…˜ ì‹¤í–‰ ë¶ˆê°€');
      return;
    }

    if (!(model as any)?.internalModel) {
      console.warn('ğŸ­ internalModelì´ ì—†ìŒ - ëª¨ë¸ì´ ì™„ì „íˆ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ');
      return;
    }

    try {
      const coreModel = (model as any).internalModel?.coreModel || (model as any).internalModel?._coreModel || (model as any)._coreModel;

      if (!coreModel) {
        console.warn('ğŸ­ coreModelì„ ì°¾ì„ ìˆ˜ ì—†ìŒ');
        return;
      }

      // ì… íŒŒë¼ë¯¸í„° ì°¾ê¸° (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
      const allMouthParams = [
        // mao ëª¨ë¸ì˜ ì‹¤ì œ íŒŒë¼ë¯¸í„°ë“¤ì„ ìµœìš°ì„ ìœ¼ë¡œ ë°°ì¹˜
        'ParamA',              // mao ëª¨ë¸ì˜ ì£¼ìš” ë¦½ì‹±í¬ íŒŒë¼ë¯¸í„° (ì•„)
        'ParamO',              // mao ëª¨ë¸ì˜ ë¦½ì‹±í¬ íŒŒë¼ë¯¸í„° (ì˜¤)
        'ParamU',              // mao ëª¨ë¸ì˜ ë¦½ì‹±í¬ íŒŒë¼ë¯¸í„° (ìš°)
        'ParamE',              // mao ëª¨ë¸ì˜ ë¦½ì‹±í¬ íŒŒë¼ë¯¸í„° (ì—) 
        'ParamI',              // mao ëª¨ë¸ì˜ ë¦½ì‹±í¬ íŒŒë¼ë¯¸í„° (ì´)
        'ParamMouthUp',        // mao ëª¨ë¸ì˜ ì…ê¼¬ë¦¬ ì˜¬ë¦¼
        'ParamMouthDown',      // mao ëª¨ë¸ì˜ ì…ê¼¬ë¦¬ ì²˜ì§
        'ParamMouthAngry',     // mao ëª¨ë¸ì˜ ë¶€ì€ ì…
        // ê¸°ì¡´ ë²”ìš© íŒŒë¼ë¯¸í„°ë“¤ (ë°±ì—…ìš©)
        'ParamMouthOpenY',     // ê¸°ë³¸ Live2D í‘œì¤€
        'ParamMouthOpen',      // ë‹¤ë¥¸ ë³€í˜•
        'MouthOpenY',          // ì§§ì€ ë²„ì „
        'MouthOpen',           // ê°€ì¥ ê°„ë‹¨í•œ ë²„ì „
        'PARAM_MOUTH_OPEN_Y',  // ëŒ€ë¬¸ì ë²„ì „
        'PARAM_MOUTH_OPEN',    // ëŒ€ë¬¸ì ë‹¨ìˆœ ë²„ì „
        'mouth_open_y',        // ì†Œë¬¸ì ìŠ¤ë„¤ì´í¬ ì¼€ì´ìŠ¤
        'mouth_open',          // ì†Œë¬¸ì ë‹¨ìˆœ
        'PARAM_A',             // ëŒ€ë¬¸ì ë²„ì „
        'ParamLipSync',        // ì§ì ‘ì ì¸ ë¦½ì‹±í¬
        'LipSync',             // ê°„ë‹¨í•œ ë²„ì „
        'param_mouth_open_y',  // ì†Œë¬¸ì ì „ì²´
        'ParamMouthY'          // Yì¶• ì… ì—´ê¸°
      ];

      let mouthOpenParam = -1;
      let usedParamName = '';
      let mouthParamMin = 0;  // mao ëª¨ë¸ íŒŒë¼ë¯¸í„° ë²”ìœ„ì— ë§ê²Œ ìˆ˜ì •
      let mouthParamMax = 1;  // mao ëª¨ë¸ íŒŒë¼ë¯¸í„° ë²”ìœ„ì— ë§ê²Œ ìˆ˜ì •

      for (const paramName of allMouthParams) {
        let paramIndex = -1;
        try {
          if (coreModel?.getParameterIndex) {
            paramIndex = coreModel.getParameterIndex(paramName);
          } else if (coreModel?.getParameterIndexById) {
            paramIndex = coreModel.getParameterIndexById(paramName);
          }
        } catch (error) {
          continue;
        }

        if (paramIndex !== undefined && paramIndex >= 0) {
          mouthOpenParam = paramIndex;
          usedParamName = paramName;

          // íŒŒë¼ë¯¸í„° ë²”ìœ„ ì¡°íšŒ
          try {
            if (coreModel.getParameterMinimumValueByIndex) {
              mouthParamMin = coreModel.getParameterMinimumValueByIndex(paramIndex);
              mouthParamMax = coreModel.getParameterMaximumValueByIndex(paramIndex);
            } else if (coreModel.getParameterMinValueByIndex) {
              mouthParamMin = coreModel.getParameterMinValueByIndex(paramIndex);
              mouthParamMax = coreModel.getParameterMaxValueByIndex(paramIndex);
            } else {
              mouthParamMin = 0; // mao ëª¨ë¸ íŒŒë¼ë¯¸í„° ë²”ìœ„ì— ë§ê²Œ ìˆ˜ì •
              mouthParamMax = 1; // mao ëª¨ë¸ íŒŒë¼ë¯¸í„° ë²”ìœ„ì— ë§ê²Œ ìˆ˜ì •
            }
          } catch (error) {
            mouthParamMin = 0; // mao ëª¨ë¸ íŒŒë¼ë¯¸í„° ë²”ìœ„ì— ë§ê²Œ ìˆ˜ì •
            mouthParamMax = 1; // mao ëª¨ë¸ íŒŒë¼ë¯¸í„° ë²”ìœ„ì— ë§ê²Œ ìˆ˜ì •
          }
          break;
        }
      }

      if (mouthOpenParam < 0) {
        console.warn('ğŸ­ ì… íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ');
        return;
      }

      console.log('ğŸ­ ì… íŒŒë¼ë¯¸í„° í™•ì¸:', {
        coreModelExists: !!coreModel,
        mouthOpenParam,
        usedParamName,
        paramFound: mouthOpenParam >= 0,
        paramRange: `${mouthParamMin} ~ ${mouthParamMax}`
      });

      if (isMoving) {
        let zeroVolumeFrameCount = 0;

        // ğŸµ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë³¼ë¥¨ ê¸°ë°˜ ì• ë‹ˆë©”ì´ì…˜
        const animate = () => {
          if (!isMoving || !animationFrameRef.current || !analyzerRef.current || !volumeDataRef.current) {
            return;
          }

          // ğŸ”Š ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ë° ë¶„ì„ê¸° ì„¤ì • (ì¤‘ë³µ ë°©ì§€)
          if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
            try {
              audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)();
              audioContextRef.current.resume(); // ì‚¬ìš©ì ì œìŠ¤ì²˜ í›„ í™œì„±í™”

              analyzerRef.current = audioContextRef.current.createAnalyser();
              // ì£¼íŒŒìˆ˜ ë¶„ì„ ì •í™•ë„ ê°œì„ 
              analyzerRef.current.fftSize = 512; // ë” ì„¸ë°€í•œ ì£¼íŒŒìˆ˜ ë¶„ì„
              analyzerRef.current.smoothingTimeConstant = 0.3; // ë¹ ë¥¸ ë°˜ì‘
              analyzerRef.current.minDecibels = -90; // ë„“ì€ ë™ì  ë²”ìœ„
              analyzerRef.current.maxDecibels = -10;

              volumeDataRef.current = new Float32Array(analyzerRef.current.frequencyBinCount);

              // ì´ˆê¸°í™” ì™„ë£Œ ë¡œê·¸ëŠ” í•œ ë²ˆë§Œ ì¶œë ¥
              console.log('ğŸ”Š ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ ì´ˆê¸°í™” ì™„ë£Œ (ìµœì´ˆ)');
            } catch (error) {
              console.warn('ğŸ”Š ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
              return;
            }
          }

          // ì˜¤ë””ì˜¤ ì£¼íŒŒìˆ˜ ë°ì´í„° ë¶„ì„ (ë¹„ì„¸ì„ ì„ íƒìš©)
          analyzerRef.current.getFloatFrequencyData(volumeDataRef.current as any);

          // ì£¼íŒŒìˆ˜ ê¸°ë°˜ ë¹„ì„¸ì„ ì„ íƒ
          let selectedViseme = selectVisemeFromFrequency(volumeDataRef.current as any);

          // ğŸš¨ ë¬´ìŒ ê°ì§€ ë° í´ë°± (CORS ë¬¸ì œ ë“±ìœ¼ë¡œ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ 0ì¼ ë•Œ)
          if (selectedViseme.value < 0.01) {
            zeroVolumeFrameCount++;
            // ì•½ 0.2ì´ˆ(12í”„ë ˆì„) ì´ìƒ ë¬´ìŒì´ê³  ë§í•˜ëŠ” ì¤‘ì´ë©´ ê°€ì§œ ë¦½ì‹±í¬ ìƒì„±
            if (zeroVolumeFrameCount > 12) {
              const time = Date.now() / 150; // ì†ë„ ì¡°ì ˆ
              // ì‚¬ì¸íŒŒ ê¸°ë°˜ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì… ì›€ì§ì„ ìƒì„± (0.1 ~ 0.7 ë²”ìœ„)
              const fakeValue = (Math.sin(time) * 0.5 + 0.5) * 0.6 + 0.1;

              // ëœë¤í•˜ê²Œ ëª¨ìŒ ë³€ê²½ (ì¡°ê¸ˆ ë” ìì—°ìŠ¤ëŸ½ê²Œ)
              const vowels = ['ParamA', 'ParamO', 'ParamE'];
              const randomVowel = vowels[Math.floor((Date.now() / 500) % vowels.length)];

              selectedViseme = {
                param: randomVowel,
                value: fakeValue,
                name: 'Simulated(Fallback)'
              };

              if (Math.random() < 0.05) {
                console.log('ğŸ­ ì˜¤ë””ì˜¤ ë°ì´í„° ì—†ìŒ - ì‹œë®¬ë ˆì´ì…˜ ë¦½ì‹±í¬ ì‘ë™ ì¤‘');
              }
            }
          } else {
            zeroVolumeFrameCount = 0; // ì†Œë¦¬ê°€ ê°ì§€ë˜ë©´ ì¹´ìš´í„° ë¦¬ì…‹
          }

          // ì„ íƒëœ ë¹„ì„¸ì„ ì ìš©
          applyRealtimeViseme(selectedViseme);

          // 1% í™•ë¥ ë¡œ ë¡œê·¸ (ì„±ëŠ¥ ê°œì„ , ë¬´ìŒ ìƒíƒœ ì œì™¸)
          if (Math.random() < 0.01 && selectedViseme.value > 0.005) {
            console.log(`ğŸµ ì‹¤ì‹œê°„ ë¹„ì„¸ì„: ${selectedViseme.name} (${selectedViseme.param}=${selectedViseme.value.toFixed(2)})`);
          }

          animationFrameRef.current = requestAnimationFrame(animate);
        };

        // ì˜¤ë””ì˜¤ ë¶„ì„ê¸°ê°€ ì¤€ë¹„ë˜ì—ˆìœ¼ë©´ ë³¼ë¥¨ ê¸°ë°˜ ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘
        if (analyzerRef.current && volumeDataRef.current) {
          console.log('ğŸµ ë³¼ë¥¨ ê¸°ë°˜ ë¦½ì‹±í¬ ì‹œì‘');
          animationFrameRef.current = requestAnimationFrame(animate);
        } else {
          // ì˜¤ë””ì˜¤ ë¶„ì„ê¸°ê°€ ì—†ìœ¼ë©´ ë°±ì—… ì• ë‹ˆë©”ì´ì…˜ (ë‹¤ì–‘í•œ ë¹„ì„¸ì„ ìˆœí™˜)
          console.log('ğŸ­ ë°±ì—… ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘ (ë‹¤ì–‘í•œ ë¹„ì„¸ì„ ìˆœí™˜)');
          let animationStep = 0;
          const visemeSequence = [
            { param: 'ParamA', name: 'ã…(ì•„)' },
            { param: 'ParamO', name: 'ã…—(ì˜¤)' },
            { param: 'ParamE', name: 'ã…”(ì—)' },
            { param: 'ParamI', name: 'ã…£(ì´)' },
            { param: 'ParamU', name: 'ã…œ(ìš°)' }
          ];

          const backupAnimate = () => {
            if (!isMoving || !animationFrameRef.current) return;

            animationStep += 0.1;
            const baseIntensity = Math.sin(animationStep) * 0.5 + 0.5; // 0~1 ì‚¬ì´ì˜ ê°•ë„

            // ì‹œê°„ì— ë”°ë¼ ë¹„ì„¸ì„ ìˆœí™˜ ì„ íƒ
            const visemeIndex = Math.floor((animationStep * 2) % visemeSequence.length);
            const currentViseme = visemeSequence[visemeIndex];

            // ì„ íƒëœ ë¹„ì„¸ì„ì— ê°•ë„ ì ìš©
            const selectedViseme = {
              param: currentViseme.param,
              value: baseIntensity * 0.8, // ë°±ì—…ì€ ì•½ê°„ ì•½í•˜ê²Œ
              name: currentViseme.name + '-ë°±ì—…'
            };

            applyRealtimeViseme(selectedViseme);

            if (Math.floor(animationStep * 10) % 50 === 0) {
              console.log(`ğŸ­ ë°±ì—… ë¹„ì„¸ì„: ${selectedViseme.name} (ê°•ë„: ${selectedViseme.value.toFixed(2)})`);
            }

            animationFrameRef.current = requestAnimationFrame(backupAnimate);
          };
          animationFrameRef.current = requestAnimationFrame(backupAnimate);
        }
      } else {
        // ì… ë‹«ê¸° - ëª¨ë“  ë¹„ì„¸ì„ íŒŒë¼ë¯¸í„°ë¥¼ 0ìœ¼ë¡œ ì„¤ì •
        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current);
          animationFrameRef.current = null;
        }

        // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°
        applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });
        console.log('ğŸ­ ëª¨ë“  ë¹„ì„¸ì„ ë‹«ê¸° ì™„ë£Œ');
      }
    } catch (error) {
      console.error('ë¹„ì„¸ì„ ê¸°ë°˜ animateMouth ì˜¤ë¥˜:', error);
    }
  }, [model, selectVisemeFromFrequency, applyRealtimeViseme]);

  // íŒŒë¼ë¯¸í„° ìºì‹œ (í•œ ë²ˆ ì°¾ìœ¼ë©´ ì €ì¥í•˜ì—¬ ì¤‘ë³µ íƒìƒ‰ ë°©ì§€)
  const mouthParamCache = useRef<{ index: number; name: string } | null>(null);

  // ëª¨ë¸ ë³€ê²½ ì‹œ ìºì‹œ ì´ˆê¸°í™”
  useEffect(() => {
    if (mouthParamCache.current) {
      console.log('ğŸ”„ ëª¨ë¸ ë³€ê²½ìœ¼ë¡œ íŒŒë¼ë¯¸í„° ìºì‹œ ì´ˆê¸°í™”');
      mouthParamCache.current = null;
    }
  }, [model]);

  // íŠ¹ì • ë³¼ë¥¨ ê°’ìœ¼ë¡œ ì… ì›€ì§ì„ ì„¤ì • (ë³¼ë¥¨ ë°°ì—´ ê¸°ë°˜ ë¦½ì‹±í¬ìš©)
  const animateMouthWithVolumeValue = useCallback((volume: number) => {
    if (!model) {
      console.warn('ğŸ­ ëª¨ë¸ì´ ì—†ì–´ì„œ ë³¼ë¥¨ ê¸°ë°˜ ë¹„ì„¸ì„ ì„¤ì • ë¶ˆê°€');
      return;
    }

    // ê°„ë‹¨í•œ ë³¼ë¥¨ ê¸°ë°˜ ë¹„ì„¸ì„ ì ìš© (ê¸°ë³¸ì ìœ¼ë¡œ ParamA ì‚¬ìš©)
    const normalizedVolume = Math.max(0, Math.min(1, volume));

    if (normalizedVolume > 0) {
      // ë³¼ë¥¨ì´ ìˆìœ¼ë©´ ê¸°ë³¸ ë¹„ì„¸ì„(ParamA) ì ìš©
      applyRealtimeViseme({
        param: 'ParamA',
        value: normalizedVolume,
        name: 'ã…(ì•„)-ë³¼ë¥¨'
      });
    } else {
      // ë³¼ë¥¨ì´ ì—†ìœ¼ë©´ ì… ë‹«ê¸°
      applyRealtimeViseme({
        param: 'ParamA',
        value: 0,
        name: 'ë¬´ìŒ'
      });
    }
  }, [model, applyRealtimeViseme]);

  // ë³¼ë¥¨ ë°°ì—´ ê¸°ë°˜ ë¦½ì‹±í¬ ì¬ìƒ
  const speakWithVolumeData = useCallback((audioUrl: string, volumes: number[]) => {
    console.log('ğŸµ ë³¼ë¥¨ ë°ì´í„° ê¸°ë°˜ TTS ì¬ìƒ:', {
      audioUrl: audioUrl.substring(0, 50) + '...',
      volumeCount: volumes.length,
      sampleVolumes: volumes.slice(0, 10)
    });

    try {
      const audio = new Audio(audioUrl);
      audio.crossOrigin = 'anonymous';
      setIsSpeaking(true);

      let volumeIndex = 0;
      // let intervalId: NodeJS.Timeout | null = null; // intervalRef ì‚¬ìš©
      let audioContext: AudioContext | null = null;
      let analyzer: AnalyserNode | null = null;
      let source: MediaElementAudioSourceNode | null = null;

      // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ ì„¤ì • (ë°±ì—… ë° ë³´ì •ìš©)
      const setupRealtimeAnalysis = async () => {
        try {
          audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
          analyzer = audioContext.createAnalyser();

          // ì£¼íŒŒìˆ˜ ë¶„ì„ ì •í™•ë„ ê°œì„ 
          analyzer.fftSize = 512; // ë” ì„¸ë°€í•œ ì£¼íŒŒìˆ˜ ë¶„ì„ (256ê°œ ë¹ˆ)
          analyzer.smoothingTimeConstant = 0.3; // ë¶€ë“œëŸ¬ìš´ ë³€í™” (0.8ì—ì„œ ë‚®ì¶¤)
          analyzer.minDecibels = -90; // ë” ë„“ì€ ë™ì  ë²”ìœ„
          analyzer.maxDecibels = -10;

          source = audioContext.createMediaElementSource(audio);
          source.connect(analyzer);
          analyzer.connect(audioContext.destination);

          console.log('ğŸµ í•˜ì´ë¸Œë¦¬ë“œ ì˜¤ë””ì˜¤ ë¶„ì„ ì„¤ì • ì™„ë£Œ');
        } catch (analysisError) {
          console.warn('ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ ì„¤ì • ì‹¤íŒ¨:', analysisError);
          analyzer = null;
          audioContext = null;
        }
      };

      audio.oncanplay = () => {
        console.log('ğŸµ ì˜¤ë””ì˜¤ ì¬ìƒ ì¤€ë¹„ ì™„ë£Œ - ë¦½ì‹±í¬ ëŒ€ê¸°ì¤‘');
        setupRealtimeAnalysis(); // ì‹¤ì‹œê°„ ë¶„ì„ ì¤€ë¹„
      };

      let indexScale = 1.0;

      audio.onloadedmetadata = () => {
        if (audio.duration && volumes.length > 0) {
          const audioDurationMs = audio.duration * 1000;
          const volumesDurationMs = volumes.length * 20;
          // ì˜¤ë””ì˜¤ ê¸¸ì´ì™€ ë³¼ë¥¨ ë°ì´í„° ê¸¸ì´ê°€ ë‹¤ë¥¼ ê²½ìš° ìŠ¤ì¼€ì¼ë§ (ì‹±í¬ ë³´ì •)
          if (audioDurationMs > 0) {
            indexScale = volumesDurationMs / audioDurationMs;
            console.log(`ğŸµ ì‹±í¬ ë³´ì • ë¹„ìœ¨: ${indexScale.toFixed(3)} (Audio: ${audioDurationMs.toFixed(0)}ms, Volumes: ${volumesDurationMs}ms)`);
          }
        }
      };

      audio.onplay = () => {
        console.log('ğŸµ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ - í•˜ì´ë¸Œë¦¬ë“œ ë¦½ì‹±í¬ ë™ê¸°í™” ì‹œì‘');

        // í•˜ì´ë¸Œë¦¬ë“œ ë¦½ì‹±í¬: ë³¼ë¥¨ ë°ì´í„° + ì‹¤ì‹œê°„ ë¶„ì„
        let zeroVolumeFrameCount = 0; // ë¬´ìŒ í”„ë ˆì„ ì¹´ìš´í„° (speakWithVolumeDataìš©)
        let currentSmoothedValue = 0; // ë¶€ë“œëŸ¬ìš´ ì›€ì§ì„ì„ ìœ„í•œ í˜„ì¬ ê°’ ì €ì¥

        // ê¸°ì¡´ ì¸í„°ë²Œ ì •ë¦¬
        if (intervalRef.current) clearInterval(intervalRef.current);

        intervalRef.current = setInterval(() => {
          let selectedViseme = { param: 'ParamA', value: 0, name: 'ë¬´ìŒ' };

          // ì˜¤ë””ì˜¤ í˜„ì¬ ì‹œê°„ ê¸°ë°˜ìœ¼ë¡œ ì¸ë±ìŠ¤ ê³„ì‚° (20ms ë‹¨ìœ„ - ë°±ì—”ë“œ ì„¤ì •ê³¼ ì¼ì¹˜)
          // indexScaleì„ ì ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ê¸¸ì´ì™€ ë³¼ë¥¨ ë°ì´í„° ê¸¸ì´ë¥¼ ë§ì¶¤
          const currentTimeMs = audio.currentTime * 1000;
          const calculatedIndex = Math.floor((currentTimeMs * indexScale) / 20);

          // ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ (ì‹œê°„ ê¸°ë°˜)
          volumeIndex = calculatedIndex;

          // ì‹¤ì‹œê°„ ì£¼íŒŒìˆ˜ ë¶„ì„ìœ¼ë¡œ ë¹„ì„¸ì„ ì¢…ë¥˜ ê²°ì • (í•­ìƒ ì‹¤í–‰)
          if (analyzer && audioContext) {
            const frequencyData = new Float32Array(analyzer.frequencyBinCount);
            analyzer.getFloatFrequencyData(frequencyData);

            // ì£¼íŒŒìˆ˜ ê¸°ë°˜ ë¹„ì„¸ì„ ì„ íƒ (ë¹„ì„¸ì„ ì¢…ë¥˜ ê²°ì •)
            const frequencyBasedViseme = selectVisemeFromFrequency(frequencyData);

            // ë³¼ë¥¨ ë°ì´í„°ë¡œ ê°•ë„ ë³´ì •
            if (volumeIndex < volumes.length) {
              const volumeIntensity = volumes[volumeIndex];
              selectedViseme = {
                param: frequencyBasedViseme.param, // ì£¼íŒŒìˆ˜ë¡œ ê²°ì •ëœ ë¹„ì„¸ì„ ì¢…ë¥˜
                // ë³¼ë¥¨ ë°ì´í„° ëŒ€í­ ì¦í­ (x3.0) ë° ì£¼íŒŒìˆ˜ ë°ì´í„° ë°˜ì˜
                value: Math.max(volumeIntensity * 3.0, frequencyBasedViseme.value * 0.6),
                name: `${frequencyBasedViseme.name}-í•˜ì´ë¸Œë¦¬ë“œ`
              };
            } else {
              // ë³¼ë¥¨ ë°ì´í„° ì—†ìœ¼ë©´ ìˆœìˆ˜ ì£¼íŒŒìˆ˜ ê¸°ë°˜ (ì¦í­)
              selectedViseme = {
                ...frequencyBasedViseme,
                value: frequencyBasedViseme.value * 2.0
              };
            }
          } else if (volumeIndex < volumes.length) {
            // ì£¼íŒŒìˆ˜ ë¶„ì„ ì—†ìœ¼ë©´ ë³¼ë¥¨ ë°ì´í„°ë§Œ (ê¸°ì¡´ ë°©ì‹, ParamAë§Œ ì‚¬ìš©)
            const volumeData = volumes[volumeIndex];
            selectedViseme = { param: 'ParamA', value: volumeData * 3.0, name: 'ã…(ì•„)-ë³¼ë¥¨ë°ì´í„°' };
          }

          // ğŸš¨ ë¬´ìŒ ê°ì§€ ë° í´ë°± (speakWithVolumeData ë‚´ë¶€ìš©)
          // ì„ê³„ê°’ì„ 0.2ë¡œ ìœ ì§€
          if (selectedViseme.value < 0.2 && !audio.paused && !audio.ended) {
            zeroVolumeFrameCount++;
            // ì•½ 0.05ì´ˆ(3í”„ë ˆì„) ì´ìƒ ë¬´ìŒì´ë©´ ê°€ì§œ ë¦½ì‹±í¬ ìƒì„± (ë°˜ì‘ì„± ë†’ì„)
            if (zeroVolumeFrameCount > 3) {
              const time = Date.now() / 300; // ì†ë„ ì¡°ì ˆ (ëŠë¦¬ê²Œ ìœ ì§€)
              // ì‚¬ì¸íŒŒ ê¸°ë°˜ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì… ì›€ì§ì„ ìƒì„± (í¬ê²Œ ì›€ì§ì´ë„ë¡: 0.3 ~ 0.8)
              const fakeValue = (Math.sin(time) * 0.5 + 0.5) * 0.5 + 0.3;

              // ëœë¤í•˜ê²Œ ëª¨ìŒ ë³€ê²½
              const vowels = ['ParamA', 'ParamO', 'ParamE'];
              const randomVowel = vowels[Math.floor((Date.now() / 1000) % vowels.length)];

              selectedViseme = {
                param: randomVowel,
                value: fakeValue,
                name: 'Simulated(Fallback-Volume)'
              };
            }
          } else {
            zeroVolumeFrameCount = 0;
          }

          // âœ… ìµœì†Œ ê°œë°© ë³´ì¥ ë° ì§€ì†ì ì¸ ì›€ì§ì„ ê°•ì œ (ì •ì  ê°’ ëŒ€ì‹  ë™ì  íŒŒë™ ì‚¬ìš©)
          if (!audio.paused && !audio.ended) {
            // ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ 0.3 ~ 0.6 ì‚¬ì´ë¥¼ ì˜¤ê°€ëŠ” íŒŒë™ ìƒì„±
            const continuousMotionTime = Date.now() / 200;
            const dynamicMin = (Math.sin(continuousMotionTime) * 0.5 + 0.5) * 0.3 + 0.3;

            // ë³¼ë¥¨ ë°ì´í„°ê°€ ë‚®ì•„ë„ ì´ ë™ì  íŒŒë™ì„ ë”°ë¼ê°€ê²Œ í•˜ì—¬ "ê³„ì† ì›€ì§ì´ëŠ”" íš¨ê³¼ ì—°ì¶œ
            selectedViseme.value = Math.max(selectedViseme.value, dynamicMin);
          }

          // ğŸŒŠ ì›€ì§ì„ ë¶€ë“œëŸ½ê²Œ ë§Œë“¤ê¸° (Lerp: Linear Interpolation)
          // ëª©í‘œ ê°’ìœ¼ë¡œ 8%ì”© ì´ë™í•˜ì—¬ í›¨ì”¬ ë” ë¶€ë“œëŸ½ê³  ì²œì²œíˆ (ê¸°ì¡´ 15%ì—ì„œ ê°ì†Œ)
          const smoothingFactor = 0.08;
          currentSmoothedValue = currentSmoothedValue * (1 - smoothingFactor) + selectedViseme.value * smoothingFactor;

          // ë¶€ë“œëŸ¬ìš´ ê°’ ì ìš©
          selectedViseme.value = currentSmoothedValue;

          // ì„ íƒëœ ë¹„ì„¸ì„ ì ìš©
          applyRealtimeViseme(selectedViseme);

          // 1% í™•ë¥ ë¡œ ë¡œê·¸ (ì„±ëŠ¥ ê°œì„ , ë¬´ìŒ ìƒíƒœ ì œì™¸)
          if (Math.random() < 0.01 && selectedViseme.value > 0.005) {
            console.log(`ğŸ”Š í•˜ì´ë¸Œë¦¬ë“œ ë¹„ì„¸ì„: ${volumeIndex}/${volumes.length} (${selectedViseme.name}: ${selectedViseme.value.toFixed(3)})`);
          }

          // ì˜¤ë””ì˜¤ê°€ ëë‚¬ëŠ”ì§€ í™•ì¸ (ë³¼ë¥¨ ë°ì´í„° ì¸ë±ìŠ¤ ì´ˆê³¼ ë° ì˜¤ë””ì˜¤ ì¢…ë£Œ ìƒíƒœ)
          if (audio.ended || (volumeIndex >= volumes.length + 50)) { // ì—¬ìœ  ë²„í¼ ëŠ˜ë¦¼
            // ì—¬ê¸°ì„œ ì¢…ë£Œí•˜ì§€ ì•Šê³  audio.onendedì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•¨ (ì•ˆì „ì¥ì¹˜)
          }
        }, 16); // 60fps ì—…ë°ì´íŠ¸ ì£¼ê¸°ëŠ” ìœ ì§€í•˜ë˜, ë°ì´í„° ìƒ˜í”Œë§ì€ ì‹œê°„ ê¸°ë°˜ìœ¼ë¡œ í•¨
      };

      audio.onended = () => {
        console.log('ğŸµ ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ');
        if (intervalRef.current) {
          clearInterval(intervalRef.current);
          intervalRef.current = null;
        }

        // í•˜ì´ë¸Œë¦¬ë“œ ë¦½ì‹±í¬ ì •ë¦¬
        if (audioContext) {
          audioContext.close();
          audioContext = null;
        }
        if (source) {
          source.disconnect();
          source = null;
        }
        analyzer = null;

        // ì•½ê°„ì˜ ì§€ì—° í›„ ì… ë‹«ê¸° (ìì—°ìŠ¤ëŸ½ê²Œ)
        setTimeout(() => {
          // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°
          applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });
          setIsSpeaking(false);
        }, 200);
      };

      audio.onerror = (error) => {
        console.error('ğŸµ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', error);
        if (intervalRef.current) {
          clearInterval(intervalRef.current);
          intervalRef.current = null;
        }

        // í•˜ì´ë¸Œë¦¬ë“œ ë¦½ì‹±í¬ ì •ë¦¬
        if (audioContext) {
          audioContext.close();
          audioContext = null;
        }
        if (source) {
          source.disconnect();
          source = null;
        }
        analyzer = null;

        // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°  
        applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });
        setIsSpeaking(false);
      };

      // ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘
      audio.play().catch(error => {
        console.error('ğŸµ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', error);
        if (intervalRef.current) {
          clearInterval(intervalRef.current);
          intervalRef.current = null;
        } animateMouthWithVolumeValue(0);
        setIsSpeaking(false);
      });

    } catch (error) {
      console.error('ğŸµ ë³¼ë¥¨ ê¸°ë°˜ TTS ì„¤ì • ì˜¤ë¥˜:', error);
      // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°
      applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });
      setIsSpeaking(false);
    }
  }, [applyRealtimeViseme]);

  // TTS ë§í•˜ê¸° ê¸°ëŠ¥ (ë³¼ë¥¨ ë°ì´í„° ì§€ì›)
  const speak = useCallback((input: string, type: 'text' | 'audio' = 'text', volumes?: number[]) => {
    console.log('ğŸ¤ TTS í˜¸ì¶œ:', type, volumes ? `(${volumes.length}ê°œ ë³¼ë¥¨)` : '');

    // ê¸°ì¡´ ìŒì„±/ì• ë‹ˆë©”ì´ì…˜ ì¤‘ë‹¨ ë° ì •ë¦¬
    stopSpeaking();

    if (!input.trim()) {
      // ë¹ˆ ì…ë ¥ - ì‹¤í–‰ ì•ˆí•¨ (ë¡œê·¸ ì œê±°)
      return;
    }

    // ğŸµ OpenAI TTS ì˜¤ë””ì˜¤ ì¬ìƒ
    if (type === 'audio') {
      // 1ìˆœìœ„: ë³¼ë¥¨ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë³¼ë¥¨ ê¸°ë°˜ ë¦½ì‹±í¬ ì‚¬ìš©
      if (volumes && volumes.length > 0) {
        console.log('ğŸµ ë³¼ë¥¨ ë°ì´í„° ê¸°ë°˜ ì¬ìƒ ì„ íƒ');
        speakWithVolumeData(input, volumes);
        return;
      }

      // 2ìˆœìœ„: ë³¼ë¥¨ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‹¤ì‹œê°„ ë¶„ì„ ë°©ì‹ (ê¸°ì¡´ ë°©ì‹)
      console.log('ğŸµ ì‹¤ì‹œê°„ ë¶„ì„ ì¬ìƒ (ë³¼ë¥¨ ë°ì´í„° ì—†ìŒ)');

      try {
        const audio = new Audio(input);
        audio.crossOrigin = 'anonymous';

        // ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™”
        initializeAudioAnalysis();

        // Web Audio APIë¡œ ì˜¤ë””ì˜¤ ë¶„ì„
        if (audioContextRef.current && analyzerRef.current) {
          const source = audioContextRef.current.createMediaElementSource(audio);
          source.connect(analyzerRef.current);
          analyzerRef.current.connect(audioContextRef.current.destination);

          console.log('ğŸµ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ ì—°ê²° ì™„ë£Œ');
        }

        setIsSpeaking(true);

        audio.onloadstart = () => {
          console.log('ğŸµ OpenAI TTS ì˜¤ë””ì˜¤ ë¡œë”© ì‹œì‘');
        };

        audio.oncanplay = () => {
          console.log('ğŸµ OpenAI TTS ì˜¤ë””ì˜¤ ì¬ìƒ ê°€ëŠ¥');
          // ì‹¤ì‹œê°„ ë¶„ì„ ëª¨ë“œë¡œ ë‹¤ì–‘í•œ ë¹„ì„¸ì„ ì ìš©
          animateMouthWithVolume(true);
        };

        audio.onplay = () => {
          console.log('ğŸµ OpenAI TTS ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘');
        };

        audio.onended = () => {
          console.log('ğŸµ OpenAI TTS ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ');
          // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°
          applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });
          setIsSpeaking(false);
        };

        audio.onerror = (error) => {
          console.error('ğŸµ OpenAI TTS ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', error);
          // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°
          applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });
          setIsSpeaking(false);
        };

        // ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘
        audio.play().catch(error => {
          console.error('ğŸµ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', error);
          animateMouthWithVolume(false);
          setIsSpeaking(false);
        });

        return; // OpenAI TTS ì¬ìƒì‹œ ì—¬ê¸°ì„œ ì¢…ë£Œ

      } catch (error) {
        console.error('ğŸµ OpenAI TTS ì„¤ì • ì˜¤ë¥˜:', error);
        return;
      }
    }

    // ğŸ¤ ë¸Œë¼ìš°ì € TTS (ë°±ì—… ë˜ëŠ” í…ìŠ¤íŠ¸ íƒ€ì…)
    console.log('ğŸ¤ ë¸Œë¼ìš°ì € TTS ì‹œì‘');

    const finalText = input.trim();

    // ê°ì • ëª…ë ¹ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì œê±° (ì•ˆì „ì¥ì¹˜)
    const { cleanText } = parseEmotionMessage(input);
    const finalTextForTTS = cleanText || finalText;

    // ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” (ë¸Œë¼ìš°ì € TTSìš©)
    initializeAudioAnalysis();

    // TTS ê¶Œí•œ í™œì„±í™”
    if ('speechSynthesis' in window) {
      try {
        const testUtterance = new SpeechSynthesisUtterance('');
        testUtterance.volume = 0;
        window.speechSynthesis.speak(testUtterance);
        window.speechSynthesis.cancel();
        console.log('ğŸ¤ TTS ê¶Œí•œ í™œì„±í™” ì™„ë£Œ');
      } catch (error) {
        console.warn('ğŸ¤ TTS ê¶Œí•œ í™œì„±í™” ì‹¤íŒ¨:', error);
      }
    }

    const utterance = new SpeechSynthesisUtterance(finalTextForTTS);
    const voices = window.speechSynthesis.getVoices();
    const koreanVoice = voices.find(voice => voice.lang.includes('ko'));

    if (koreanVoice) {
      utterance.voice = koreanVoice;
    }

    utterance.lang = 'ko-KR';
    utterance.rate = 0.9;
    utterance.pitch = 1.1;
    utterance.volume = 1.0;

    // ê¸°ì¡´ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤ ì €ì¥
    const originalOnEnd = utterance.onend;
    const originalOnError = utterance.onerror;

    setIsSpeaking(true);

    // ë°±ì—… ì• ë‹ˆë©”ì´ì…˜ íƒ€ì´ë¨¸ (5ì´ˆ)
    const backupTimer = setTimeout(() => {
      if (!isSpeaking && utteranceRef.current === utterance) {
        console.log('âš ï¸ TTSê°€ 5ì´ˆ í›„ì—ë„ ì‹œì‘ë˜ì§€ ì•ŠìŒ - ë°±ì—… ì• ë‹ˆë©”ì´ì…˜ ì‹¤í–‰');
        setIsSpeaking(true);
        animateMouthWithVolume(true);

        const duration = Math.min(finalText.length * 80, 8000);
        console.log(`ğŸ­ ë°±ì—… ì• ë‹ˆë©”ì´ì…˜ ì‹¤í–‰: ${duration}ms`);
        setTimeout(() => {
          console.log('ğŸ­ ë°±ì—… ì• ë‹ˆë©”ì´ì…˜ ì¢…ë£Œ');
          setIsSpeaking(false);
          // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°
          applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });
        }, duration);
      } else {
        console.log('âœ… TTSê°€ ì´ë¯¸ ì‹œì‘ë˜ì—ˆìœ¼ë¯€ë¡œ ë°±ì—… ì• ë‹ˆë©”ì´ì…˜ ì·¨ì†Œ');
      }
    }, 5000);

    utterance.onstart = () => {
      console.log('ğŸ¤ TTS ìŒì„± ì¬ìƒ ì‹œì‘:', finalText.substring(0, 30) + '...');
      clearTimeout(backupTimer);

      // ğŸµ ì˜¤ë””ì˜¤ ë¶„ì„ê¸°ì™€ TTS ì—°ê²° ì‹œë„
      try {
        if (audioContextRef.current && analyzerRef.current) {
          // MediaElementSourceë¥¼ í†µí•´ TTS ì˜¤ë””ì˜¤ì™€ ì—°ê²° ì‹œë„
          // ì£¼ì˜: TTSì˜ ì§ì ‘ ì—°ê²°ì€ ë¸Œë¼ìš°ì € ì œì•½ìœ¼ë¡œ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ
          console.log('ğŸµ TTS ì˜¤ë””ì˜¤ ë¶„ì„ ì—°ê²° ì‹œë„');
        }
      } catch (error) {
        console.warn('ğŸµ TTS ì˜¤ë””ì˜¤ ë¶„ì„ ì—°ê²° ì‹¤íŒ¨:', error);
      }

      console.log('ğŸ­ ë³¼ë¥¨ ê¸°ë°˜ ì… ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘ í˜¸ì¶œ (true)');
      // ì‹¤ì‹œê°„ ë¶„ì„ ëª¨ë“œë¡œ ë‹¤ì–‘í•œ ë¹„ì„¸ì„ ì ìš©
      animateMouthWithVolume(true);
    };

    utterance.onend = (event) => {
      console.log('ğŸ¤ TTS ìŒì„± ì¬ìƒ ì™„ë£Œ');
      console.log('ğŸ­ ëª¨ë“  ë¹„ì„¸ì„ ë‹«ê¸° í˜¸ì¶œ');
      // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°
      applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });
      setIsSpeaking(false);
      clearTimeout(backupTimer);
      if (originalOnEnd) originalOnEnd.call(utterance, event);
    };

    utterance.onerror = (event) => {
      console.error('ğŸ¤ TTS ì˜¤ë¥˜:', event.error, event);
      if (event.error === 'interrupted' || event.error === 'canceled') {
        console.log('ğŸ¤ TTS ì¤‘ë‹¨ë¨ - ê³„ì† ì§„í–‰');
        return;
      }
      setIsSpeaking(false);
      console.log('ğŸ­ TTS ì˜¤ë¥˜ë¡œ ëª¨ë“  ë¹„ì„¸ì„ ë‹«ê¸°');
      // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°
      applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });
      clearTimeout(backupTimer);
      if (originalOnError) originalOnError.call(utterance, event);
    };

    utteranceRef.current = utterance;

    console.log('ğŸ¤ TTS ì¬ìƒ ëª…ë ¹ ì „ì†¡ ì‹œì‘:', {
      text: finalText.substring(0, 30) + '...',
      voice: utterance.voice?.name || 'default',
      rate: utterance.rate,
      pitch: utterance.pitch,
      volume: utterance.volume
    });

    try {
      window.speechSynthesis.speak(utterance);
      console.log('ğŸ¤ speechSynthesis.speak() í˜¸ì¶œ ì™„ë£Œ');
    } catch (error) {
      console.error('ğŸ¤ speechSynthesis.speak() í˜¸ì¶œ ì‹¤íŒ¨:', error);
      setIsSpeaking(false);
      // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°
      applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });
    }
  }, [model, isSpeaking, animateMouthWithVolume, initializeAudioAnalysis, applyRealtimeViseme, speakWithVolumeData]);

  // ìŒì„± ì¤‘ì§€
  const stopSpeaking = useCallback(() => {
    if (utteranceRef.current) {
      window.speechSynthesis.cancel();
      utteranceRef.current = null;
    }

    setIsSpeaking(false);
    // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°
    applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });

    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
  }, [applyRealtimeViseme]);

  // ì •ë¦¬
  const cleanup = useCallback(() => {
    if (utteranceRef.current) {
      window.speechSynthesis.cancel();
      utteranceRef.current = null;
    }
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
      analyzerRef.current = null;
      volumeDataRef.current = null;
    }

    // ëª¨ë“  ë¹„ì„¸ì„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì… ë‹«ê¸°
    if (model) {
      applyRealtimeViseme({ param: 'ParamA', value: 0, name: 'ë¬´ìŒ' });
    }

    setIsSpeaking(false);
    console.log('ğŸ¤ TTS ë° ì˜¤ë””ì˜¤ ë¶„ì„ ì •ë¦¬ ì™„ë£Œ');
  }, [model, applyRealtimeViseme]);

  useEffect(() => {
    return cleanup;
  }, [cleanup]);

  // í›… ë°˜í™˜ ë¡œê·¸ ì œê±° (ì„±ëŠ¥ ê°œì„ )

  return {
    speak,
    stopSpeaking,
    isSpeaking,
    cleanup
  };
}; 