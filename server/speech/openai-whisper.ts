import OpenAI from "openai";
import fs from "fs";
import path from "path";

export class OpenAIWhisperService {
  private client: OpenAI;
  private model: string;
  private language: string;

  constructor(apiKey?: string, model: string = "whisper-1", language: string = "ko") {
    if (!apiKey) {
      throw new Error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.");
    }
    
    this.client = new OpenAI({
      apiKey: apiKey
    });
    this.model = model;
    this.language = language;
    
    console.log(`ğŸ¤ OpenAI Whisper ASR ì„œë¹„ìŠ¤ ì´ˆê¸°í™”ë¨ (ëª¨ë¸: ${model}, ì–¸ì–´: ${language})`);
  }

  /**
   * ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
   */
  async transcribeFile(filePath: string): Promise<string> {
    try {
      console.log(`ğŸ§ ìŒì„± ì¸ì‹ ì‹œì‘: ${path.basename(filePath)}`);
      
      // íŒŒì¼ ì¡´ì¬ í™•ì¸
      if (!fs.existsSync(filePath)) {
        throw new Error(`íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${filePath}`);
      }

      // íŒŒì¼ í¬ê¸° í™•ì¸ (25MB ì œí•œ)
      const stats = fs.statSync(filePath);
      const fileSizeInMB = stats.size / (1024 * 1024);
      
      if (fileSizeInMB > 25) {
        throw new Error(`íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤: ${fileSizeInMB.toFixed(2)}MB (ìµœëŒ€ 25MB)`);
      }

      console.log(`ğŸ“ íŒŒì¼ ì •ë³´: í¬ê¸° ${fileSizeInMB.toFixed(2)}MB`);

      // íŒŒì¼ ìŠ¤íŠ¸ë¦¼ ìƒì„±
      const fileStream = fs.createReadStream(filePath);
      
      // OpenAI Whisper API í˜¸ì¶œ
      console.log(`ğŸš€ OpenAI Whisper API í˜¸ì¶œ ì¤‘... (ëª¨ë¸: ${this.model})`);
      
      const transcription = await this.client.audio.transcriptions.create({
        file: fileStream,
        model: this.model,
        language: this.language,
        response_format: "text",
        temperature: 0.0,
      });

      console.log(`âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ: "${transcription.substring(0, 50)}${transcription.length > 50 ? '...' : ''}"`);
      
      return transcription;
      
    } catch (error) {
      console.error(`âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨:`, error);
      
      if (error instanceof Error) {
        // OpenAI API íŠ¹ì • ì˜¤ë¥˜ ì²˜ë¦¬
        if (error.message.includes('audio file is invalid')) {
          throw new Error(`ì§€ì›ë˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.`);
        } else if (error.message.includes('rate limit')) {
          throw new Error(`API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`);
        } else if (error.message.includes('invalid api key')) {
          throw new Error(`OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.`);
        }
        
        throw new Error(`ìŒì„± ì¸ì‹ ì‹¤íŒ¨: ${error.message}`);
      } else {
        throw new Error("ì•Œ ìˆ˜ ì—†ëŠ” ìŒì„± ì¸ì‹ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
      }
    }
  }

  /**
   * ì˜¤ë””ì˜¤ ë²„í¼ë¡œ ì§ì ‘ ë³€í™˜ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
   */
  async transcribeBuffer(audioBuffer: Buffer, filename: string): Promise<string> {
    try {
      console.log(`ğŸ§ ë²„í¼ ìŒì„± ì¸ì‹ ì‹œì‘: ${filename} (${audioBuffer.length} bytes)`);
      
      if (audioBuffer.length === 0) {
        throw new Error("ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.");
      }

      // íŒŒì¼ í¬ê¸° í™•ì¸ (25MB ì œí•œ)
      const fileSizeInMB = audioBuffer.length / (1024 * 1024);
      if (fileSizeInMB > 25) {
        throw new Error(`íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤: ${fileSizeInMB.toFixed(2)}MB (ìµœëŒ€ 25MB)`);
      }

      // File ê°ì²´ ìƒì„± (Web API)
      const file = new File([audioBuffer], filename, {
        type: this.getMimeTypeFromFilename(filename)
      });
      
      console.log(`ğŸš€ OpenAI Whisper API í˜¸ì¶œ ì¤‘... (ë²„í¼ ëª¨ë“œ)`);
      
      const transcription = await this.client.audio.transcriptions.create({
        file: file,
        model: this.model,
        language: this.language,
        response_format: "text",
        temperature: 0.0,
      });

      console.log(`âœ… ë²„í¼ ìŒì„± ì¸ì‹ ì™„ë£Œ: "${transcription.substring(0, 50)}${transcription.length > 50 ? '...' : ''}"`);
      
      return transcription;
      
    } catch (error) {
      console.error(`âŒ ë²„í¼ ìŒì„± ì¸ì‹ ì‹¤íŒ¨:`, error);
      throw error;
    }
  }

  /**
   * íŒŒì¼ëª…ì—ì„œ MIME íƒ€ì… ì¶”ì¸¡
   */
  private getMimeTypeFromFilename(filename: string): string {
    const ext = path.extname(filename).toLowerCase();
    
    const mimeTypes: { [key: string]: string } = {
      '.mp3': 'audio/mpeg',
      '.wav': 'audio/wav',
      '.ogg': 'audio/ogg',
      '.m4a': 'audio/mp4',
      '.webm': 'audio/webm',
      '.flac': 'audio/flac',
      '.aac': 'audio/aac'
    };
    
    return mimeTypes[ext] || 'audio/wav';
  }

  /**
   * ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ í™•ì¸
   */
  isSupportedFormat(filename: string): boolean {
    const supportedExtensions = ['.mp3', '.wav', '.ogg', '.m4a', '.webm', '.flac', '.aac'];
    const ext = path.extname(filename).toLowerCase();
    return supportedExtensions.includes(ext);
  }

  /**
   * ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
   */
  async healthCheck(): Promise<boolean> {
    try {
      // ê°„ë‹¨í•œ API í‚¤ ê²€ì¦ (ì‹¤ì œ ìš”ì²­ ì—†ì´)
      return !!this.client.apiKey;
    } catch (error) {
      console.error("OpenAI Whisper ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨:", error);
      return false;
    }
  }
}

// í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
let whisperInstance: OpenAIWhisperService | null = null;

export function getOpenAIWhisperService(): OpenAIWhisperService | null {
  try {
    if (!whisperInstance && OPENAI_API_KEY) {
      whisperInstance = new OpenAIWhisperService(OPENAI_API_KEY);
    }
    return whisperInstance;
  } catch (error) {
    console.warn("âš ï¸ OpenAI Whisper ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨:", error);
    return null;
  }
} 