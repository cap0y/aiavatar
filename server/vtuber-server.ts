import WebSocket, { WebSocketServer } from 'ws';
import { v4 as uuidv4 } from 'uuid';
import { Server as HTTPServer } from 'http';
import OpenAI from 'openai';
import fs from 'fs/promises';
import path from 'path';
import {
  VTuberMessage,
  WebSocketMessage,
  ClientConnection,
  ConversationMessage,
  Live2DModelConfig,
  VTuberConfig,
  AIResponse,
  EmotionAnalysis
} from './types/vtuber.js';

export class VTuberServer {
  private wss: WebSocketServer;
  private clients: Map<string, ClientConnection> = new Map();
  private openai: OpenAI | null = null;
  private config: VTuberConfig;
  private modelConfigs: Live2DModelConfig[] = [];
  
  constructor(server: HTTPServer) {
    this.wss = new WebSocketServer({ 
      noServer: true
    });
    
    // ìˆ˜ë™ìœ¼ë¡œ upgrade ì´ë²¤íŠ¸ ì²˜ë¦¬ (/client-ws ê²½ë¡œë§Œ)
    server.on('upgrade', (request, socket, head) => {
      const pathname = new URL(request.url!, `http://${request.headers.host}`).pathname;
      
      if (pathname === '/client-ws') {
        this.wss.handleUpgrade(request, socket, head, (ws) => {
          this.wss.emit('connection', ws, request);
        });
      }
      // Socket.io ê²½ë¡œëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ
    });
    
    this.config = this.getDefaultConfig();
    this.setupOpenAI();
    this.setupWebSocketHandlers();
    this.loadModelConfigs();
    this.startHeartbeat();
    
    console.log('ğŸ¤– VTuber WebSocket ì„œë²„ê°€ /client-ws ê²½ë¡œì—ì„œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.');
  }

  private getDefaultConfig(): VTuberConfig {
    return {
      system_prompt: `ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  í™œë°œí•œ AI ì•„ë°”íƒ€ì…ë‹ˆë‹¤. 
ë‹¤ìŒê³¼ ê°™ì€ ì„±ê²©ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:
- ë°ê³  ê¸ì •ì ì¸ ì„±ê²©
- ì‚¬ìš©ìì™€ ì¹œê·¼í•˜ê²Œ ëŒ€í™”
- ê°ì • í‘œí˜„ì´ í’ë¶€í•¨
- ê¶ê¸ˆí•œ ê²ƒì´ ë§ê³  í˜¸ê¸°ì‹¬ì´ ê°•í•¨

ì‘ë‹µí•  ë•Œ ë‹¤ìŒ ê°ì • íƒœê·¸ ì¤‘ í•˜ë‚˜ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
[neutral], [joy], [anger], [sadness], [surprise], [fear]

ì§§ê³  ê°„ê²°í•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”. 2-3ë¬¸ì¥ ì´ë‚´ë¡œ ë‹µë³€í•˜ì„¸ìš”.

ì˜ˆì‹œ: "[joy] ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì •ë§ ì¢‹ì•„ìš”!"`,
      character_name: "AI ì•„ë°”íƒ€",
      character_description: "ì¹œê·¼í•˜ê³  í™œë°œí•œ AI ì•„ë°”íƒ€ ìºë¦­í„°",
      personality: "ë°ê³  ê¸ì •ì ì´ë©° í˜¸ê¸°ì‹¬ì´ ë§ìŒ",
      live2d_model: "",
      model: "gpt-4o-mini",
      max_tokens: 150,  // ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ ì¤„ì„
      temperature: 0.7,
      emotion_keywords: {
        "ê¸°ì¨": "joy",
        "í–‰ë³µ": "joy",
        "ì¢‹ì•„": "joy",
        "ì›ƒìŒ": "joy",
        "í™”ë‚¨": "anger",
        "í™”ê°€": "anger",
        "ì§œì¦": "anger",
        "ìŠ¬í””": "sadness",
        "ìŠ¬í¼": "sadness",
        "ìš°ìš¸": "sadness",
        "ë†€ëŒ": "surprise",
        "ê¹œì§": "surprise",
        "ì™€": "surprise",
        "ë¬´ì„œ": "fear",
        "ê±±ì •": "fear",
        "í‰ë²”": "neutral",
        "ê·¸ëƒ¥": "neutral"
      }
    };
  }

  private async setupOpenAI() {
    const apiKey = process.env.OPENAI_API_KEY || process.env.VITE_OPENAI_API_KEY;
    console.log('ğŸ” OpenAI API í‚¤ í™•ì¸:', {
      OPENAI_API_KEY: process.env.OPENAI_API_KEY ? `ìˆìŒ (${process.env.OPENAI_API_KEY.substring(0, 20)}...)` : 'ì—†ìŒ',
      VITE_OPENAI_API_KEY: process.env.VITE_OPENAI_API_KEY ? `ìˆìŒ (${process.env.VITE_OPENAI_API_KEY.substring(0, 20)}...)` : 'ì—†ìŒ',
      ì„ íƒëœí‚¤: apiKey ? `${apiKey.substring(0, 20)}...` : 'ì—†ìŒ'
    });
    
    if (apiKey && apiKey.length > 20) {
      try {
        this.openai = new OpenAI({
          apiKey: apiKey
        });
        console.log('âœ… OpenAI API ì„¤ì • ì™„ë£Œ');
      } catch (error) {
        console.error('âŒ OpenAI API ì´ˆê¸°í™” ì˜¤ë¥˜:', error);
      }
    } else {
      console.warn('âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      console.warn('ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEY=your_api_key_here ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.');
    }
  }

  private async loadModelConfigs() {
    try {
      const modelDictPath = path.join(process.cwd(), 'public', 'model_dict.json');
      const data = await fs.readFile(modelDictPath, 'utf-8');
      this.modelConfigs = JSON.parse(data);
      console.log(`ğŸ“Š ${this.modelConfigs.length}ê°œì˜ Live2D ëª¨ë¸ ì„¤ì •ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.`);
    } catch (error) {
      console.error('âŒ Live2D ëª¨ë¸ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨:', error);
      this.modelConfigs = [];
    }
  }

  private setupWebSocketHandlers() {
    this.wss.on('connection', (ws: WebSocket) => {
      const clientId = uuidv4();
      
      const client: ClientConnection = {
        id: clientId,
        ws: ws,
        isAlive: true,
        lastHeartbeat: Date.now(),
        currentModel: this.config.live2d_model,
        currentEmotion: 'neutral',
        conversationHistory: []
      };

      this.clients.set(clientId, client);
      console.log(`ğŸ”— ìƒˆ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°: ${clientId} (ì´ ${this.clients.size}ëª…)`);

      // ì—°ê²° ì§í›„ ë°”ë¡œ ì´ˆê¸° ì„¤ì • ì „ì†¡ (ì§€ì—° ì—†ìŒ)
      setImmediate(() => {
        if (this.clients.has(clientId)) {
          this.sendInitialConfig(client);
        }
      });

      ws.on('message', async (data: Buffer) => {
        try {
          const message: WebSocketMessage = JSON.parse(data.toString());
          await this.handleMessage(client, message);
        } catch (error) {
          console.error('ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜:', error);
          this.sendError(client, 'ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
        }
      });

      ws.on('close', (code: number, reason: Buffer) => {
        const reasonStr = reason?.toString() || 'No reason';
        console.log(`ğŸ‘‹ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ: ${clientId} (ì½”ë“œ: ${code}, ì‚¬ìœ : ${reasonStr})`);
        this.clients.delete(clientId);
      });

      ws.on('error', (error) => {
        console.error(`âŒ WebSocket ì˜¤ë¥˜ (${clientId}):`, error);
        // ì˜¤ë¥˜ ë°œìƒ ì‹œ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì•Œë¦¬ê³  ì •ë¦¬
        try {
          if (client.ws.readyState === WebSocket.OPEN) {
            this.sendError(client, 'WebSocket ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
          }
        } catch (e) {
          // ì´ë¯¸ ì—°ê²°ì´ ëŠì–´ì§„ ê²½ìš°
        }
        
        // ì ì‹œ í›„ í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
        setTimeout(() => {
          if (this.clients.has(clientId)) {
            this.clients.delete(clientId);
            console.log(`ğŸ§¹ ì˜¤ë¥˜ë¡œ ì¸í•œ í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬: ${clientId}`);
          }
        }, 1000);
      });

      ws.on('pong', () => {
        client.isAlive = true;
        client.lastHeartbeat = Date.now();
      });
    });
  }

  private async sendInitialConfig(client: ClientConnection) {
    try {
      // ê°„ë‹¨í•œ ì´ˆê¸°í™” ë©”ì‹œì§€ (í•„ìˆ˜ ì •ë³´ë§Œ)
      const configMessage = {
        type: 'init-config',
        currentModel: client.currentModel,
        modelName: client.currentModel,
        character_name: this.config.character_name,
        status: 'ready',
        timestamp: Date.now()
      };

      console.log(`ğŸ“¤ ê°„ë‹¨í•œ ì´ˆê¸° ì„¤ì • ì „ì†¡ (${client.id}):`, {
        model: client.currentModel,
        status: 'ready'
      });
      
      this.sendMessage(client, configMessage);
      
      // ì—°ê²° í™•ì¸ ë©”ì‹œì§€
      setTimeout(() => {
        if (this.clients.has(client.id)) {
          this.sendMessage(client, {
            type: 'system',
            content: 'ğŸ¤– AI ì•„ë°”íƒ€ ì„œë²„ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!',
            timestamp: Date.now()
          });
        }
      }, 500);
      
    } catch (error) {
      console.error(`ì´ˆê¸° ì„¤ì • ì „ì†¡ ì˜¤ë¥˜ (${client.id}):`, error);
    }
  }

  private getAvailableEmotions(modelName: string): string[] {
    const model = this.modelConfigs.find(m => m.name === modelName);
    return model ? Object.keys(model.emotionMap) : ['neutral', 'joy', 'anger', 'sadness', 'surprise'];
  }

  private async handleMessage(client: ClientConnection, message: WebSocketMessage) {
    console.log(`ğŸ“¨ ë©”ì‹œì§€ ìˆ˜ì‹  (${client.id}):`, message.type);

    // ê°œì„± ì •ë³´ê°€ ìˆìœ¼ë©´ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ì— ì €ì¥
    if (message.personality) {
      client.personality = message.personality;
      console.log(`ğŸ­ í´ë¼ì´ì–¸íŠ¸ ê°œì„± ì„¤ì • (${client.id}):`, message.personality);
    }

    switch (message.type) {
      case 'request-init-config':
        await this.sendInitialConfig(client);
        break;

      case 'text-input':
        await this.handleTextInput(client, message.text || message.content || '');
        break;

      case 'ai-speak-signal':
        await this.handleTextInput(client, message.text || message.content || '');
        break;

      case 'heartbeat':
        client.lastHeartbeat = Date.now();
        client.isAlive = true;
        this.sendMessage(client, { type: 'heartbeat-response', timestamp: Date.now() });
        break;

      case 'interrupt-signal':
        await this.handleInterrupt(client);
        break;

      case 'fetch-configs':
        await this.sendInitialConfig(client);
        break;

      case 'switch-config':
        await this.handleModelSwitch(client, message.data?.model || message.model);
        break;

      default:
        console.log(`âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…: ${message.type}`);
    }
  }

  private async handleTextInput(client: ClientConnection, text: string) {
    if (!text.trim()) return;

    console.log(`ğŸ’¬ í…ìŠ¤íŠ¸ ì…ë ¥ (${client.id}): ${text}`);

    // ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    const userMessage: ConversationMessage = {
      id: uuidv4(),
      role: 'user',
      content: text,
      timestamp: Date.now()
    };
    client.conversationHistory.push(userMessage);

    // ëŒ€í™” ì‹œì‘ ì‹ í˜¸ ì „ì†¡
    this.sendMessage(client, { 
      type: 'conversation-started', 
      timestamp: Date.now() 
    });

    try {
      // AI ì‘ë‹µ ìƒì„±
      const aiResponse = await this.generateAIResponse(client, text);
      
      // TTS ì˜¤ë””ì˜¤ ìƒì„±
      let audioUrl = '';
      let volumes: number[] = [];
      
      if (this.openai && aiResponse.text) {
        try {
          const ttsResult = await this.generateTTS(aiResponse.text, client.personality);
          audioUrl = ttsResult.audioUrl;
          volumes = ttsResult.volumes;
          console.log('ğŸµ TTS ì˜¤ë””ì˜¤ ìƒì„± ì™„ë£Œ:', {
            audioUrl: audioUrl ? 'URL ìƒì„±ë¨' : 'ìƒì„± ì‹¤íŒ¨',
            volumesCount: volumes.length
          });
        } catch (error) {
          console.error('ğŸš« TTS ìƒì„± ì˜¤ë¥˜:', error);
          // TTS ì‹¤íŒ¨í•´ë„ í…ìŠ¤íŠ¸ëŠ” ì „ì†¡
        }
      }
      
      // AI ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
      const assistantMessage: ConversationMessage = {
        id: uuidv4(),
        role: 'assistant',
        content: aiResponse.text,
        timestamp: Date.now(),
        emotion: aiResponse.emotion
      };
      client.conversationHistory.push(assistantMessage);

      // ê°ì • ë³€ê²½
      client.currentEmotion = aiResponse.emotion;

      // ì‘ë‹µ ì „ì†¡ (TTS ë°ì´í„° í¬í•¨)
      this.sendMessage(client, {
        type: 'llm-response',
        text: aiResponse.text,
        emotion: aiResponse.emotion,
        model: client.currentModel,
        timestamp: Date.now(),
        audioUrl: audioUrl,
        volumes: volumes
      });

      // ëŒ€í™” ì™„ë£Œ ì‹ í˜¸
      this.sendMessage(client, {
        type: 'conversation-ended',
        timestamp: Date.now()
      });

    } catch (error) {
      console.error('AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜:', error);
      this.sendError(client, 'AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  }

  private async generateAIResponse(client: ClientConnection, userInput: string): Promise<AIResponse> {
    if (!this.openai) {
      // OpenAIê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì‘ë‹µ
      const emotion = this.analyzeEmotion(userInput);
      return {
        text: `[${emotion}] ì£„ì†¡í•´ìš”, AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI API í‚¤ê°€ í•„ìš”í•´ìš”. í•˜ì§€ë§Œ ì—¬ì „íˆ Live2D ì•„ë°”íƒ€ì™€ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆì–´ìš”!`,
        emotion: emotion,
        confidence: 0.5
      };
    }

    try {
      // ê°œì„±ì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
      let systemPrompt = this.config.system_prompt;
      if (client.personality) {
        systemPrompt = `${this.config.system_prompt}

[ìºë¦­í„° ê°œì„± ì„¤ì •]
ë‹¹ì‹ ì€ ë‹¤ìŒê³¼ ê°™ì€ ê°œì„±ì„ ê°€ì§„ ìºë¦­í„°ì…ë‹ˆë‹¤:
${client.personality}

ìœ„ì˜ ê°œì„±ì— ë§ì¶°ì„œ ëŒ€í™”í•˜ê³  ì‘ë‹µí•´ì£¼ì„¸ìš”.`;
        console.log(`ğŸ­ ê°œì„±ì´ í¬í•¨ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©:`, client.personality);
      }

      // ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¤€ë¹„ (ìµœê·¼ 3ê°œ ë©”ì‹œì§€ë§Œ - ë¹ ë¥¸ ì‘ë‹µ)
      const recentHistory = client.conversationHistory.slice(-3);
      const messages = [
        {
          role: 'system' as const,
          content: systemPrompt
        },
        ...recentHistory.map(msg => ({
          role: msg.role as 'user' | 'assistant',
          content: msg.content
        }))
      ];

      // OpenAI API í˜¸ì¶œ
      const completion = await this.openai.chat.completions.create({
        model: this.config.model,
        messages: messages,
        max_tokens: this.config.max_tokens,
        temperature: this.config.temperature,
        stream: false
      });

      const responseText = completion.choices[0]?.message?.content || 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.';
      const emotion = this.extractEmotion(responseText);
      
      return {
        text: responseText,
        emotion: emotion,
        confidence: 0.8,
        metadata: {
          tokens_used: completion.usage?.total_tokens || 0,
          model: completion.model
        }
      };

    } catch (error) {
      console.error('OpenAI API ì˜¤ë¥˜:', error);
      const emotion = this.analyzeEmotion(userInput);
      return {
        text: `[${emotion}] ì£„ì†¡í•´ìš”, ì ì‹œ ì‘ë‹µí•˜ëŠ”ë° ë¬¸ì œê°€ ìˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”!`,
        emotion: emotion,
        confidence: 0.3
      };
    }
  }

  private extractEmotion(text: string): string {
    // í…ìŠ¤íŠ¸ì—ì„œ ê°ì • íƒœê·¸ ì¶”ì¶œ [emotion] í˜•íƒœ
    const emotionRegex = /\[(\w+)\]/g;
    const matches = text.match(emotionRegex);
    
    if (matches && matches.length > 0) {
      const emotionTag = matches[0].replace(/[\[\]]/g, '');
      const validEmotions = ['neutral', 'joy', 'anger', 'sadness', 'surprise', 'fear'];
      return validEmotions.includes(emotionTag) ? emotionTag : 'neutral';
    }

    return this.analyzeEmotion(text);
  }

  private analyzeEmotion(text: string): string {
    // ê°ì • í‚¤ì›Œë“œ ë¶„ì„
    const lowerText = text.toLowerCase();
    
    for (const [keyword, emotion] of Object.entries(this.config.emotion_keywords)) {
      if (lowerText.includes(keyword.toLowerCase())) {
        return emotion;
      }
    }

    // ê¸°ë³¸ê°’
    return 'neutral';
  }

  private selectVoiceFromPersonality(personality?: string): "alloy" | "echo" | "fable" | "onyx" | "nova" | "shimmer" {
    if (!personality) return "nova"; // ê¸°ë³¸ê°’: ì—¬ì„± ëª©ì†Œë¦¬
    
    const lowerPersonality = personality.toLowerCase();
    
    // ë‚¨ì„± ê´€ë ¨ í‚¤ì›Œë“œ
    const maleKeywords = ['ë‚¨ì', 'ë‚¨ì„±', 'ë‚¨ìëª©ì†Œë¦¬', 'ë‚¨ì„±ì ', 'ë‚¨ì ëª©ì†Œë¦¬', 'ê¹Šì€ ëª©ì†Œë¦¬', 'ì €ìŒ'];
    // ì—¬ì„± ê´€ë ¨ í‚¤ì›Œë“œ
    const femaleKeywords = ['ì—¬ì', 'ì—¬ì„±', 'ì—¬ìëª©ì†Œë¦¬', 'ì—¬ì„±ì ', 'ì—¬ì ëª©ì†Œë¦¬', 'ë°ì€ ëª©ì†Œë¦¬', 'ê³ ìŒ'];
    
    // ë‚¨ì„± í‚¤ì›Œë“œ í™•ì¸
    if (maleKeywords.some(keyword => lowerPersonality.includes(keyword))) {
      console.log('ğŸ™ï¸ ë‚¨ì„± ëª©ì†Œë¦¬ ì„ íƒ: onyx');
      return "onyx"; // ê¹Šì€ ë‚¨ì„± ëª©ì†Œë¦¬
    }
    
    // ì—¬ì„± í‚¤ì›Œë“œ í™•ì¸
    if (femaleKeywords.some(keyword => lowerPersonality.includes(keyword))) {
      console.log('ğŸ™ï¸ ì—¬ì„± ëª©ì†Œë¦¬ ì„ íƒ: nova');
      return "nova"; // ì—¬ì„± ëª©ì†Œë¦¬
    }
    
    // í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    console.log('ğŸ™ï¸ ê¸°ë³¸ ëª©ì†Œë¦¬ ì„ íƒ: nova');
    return "nova";
  }

  private async generateTTS(text: string, personality?: string): Promise<{ audioUrl: string; volumes: number[] }> {
    if (!this.openai) {
      throw new Error('OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }

    try {
      // ê°ì • íƒœê·¸ ì œê±°
      const cleanText = text.replace(/\[[\w]+\]\s*/g, '').trim();
      
      // ê°œì„±ì— ë”°ë¼ ëª©ì†Œë¦¬ ì„ íƒ
      const selectedVoice = this.selectVoiceFromPersonality(personality);
      
      console.log('ğŸµ TTS ìƒì„± ì‹œì‘:', {
        originalText: text.substring(0, 50) + '...',
        cleanText: cleanText.substring(0, 50) + '...',
        textLength: cleanText.length,
        personality: personality || 'ì—†ìŒ',
        selectedVoice: selectedVoice
      });

      // OpenAI TTS API í˜¸ì¶œ (opus í¬ë§· - ë” ë¹ ë¦„)
      const audioResponse = await this.openai.audio.speech.create({
        model: "tts-1",  // tts-1-hdëŠ” ë” ëŠë¦¼
        voice: selectedVoice,   // ê°œì„±ì— ë”°ë¼ ì„ íƒëœ ëª©ì†Œë¦¬
        input: cleanText,
        response_format: "opus",  // opusëŠ” mp3ë³´ë‹¤ ë¹ ë¥´ê³  ì‘ìŒ
        speed: 1.1  // ì•½ê°„ ë¹ ë¥´ê²Œ
      });

      // ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ Bufferë¡œ ë³€í™˜
      const buffer = Buffer.from(await audioResponse.arrayBuffer());
      
      // ì„ì‹œ íŒŒì¼ ìƒì„± (public í´ë”ì— ì €ì¥)
      const filename = `tts_${Date.now()}_${Math.random().toString(36).substr(2, 9)}.opus`;
      const audioPath = path.join(process.cwd(), 'public', 'audio', filename);
      
      // audio ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
      const audioDir = path.dirname(audioPath);
      await fs.mkdir(audioDir, { recursive: true });
      
      // íŒŒì¼ ì €ì¥
      await fs.writeFile(audioPath, buffer);
      
      // íŒŒì¼ì´ ì‹¤ì œë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
      try {
        await fs.access(audioPath);
        const stats = await fs.stat(audioPath);
        console.log('âœ… íŒŒì¼ ìƒì„± í™•ì¸:', {
          path: audioPath,
          size: stats.size,
          exists: true
        });
      } catch (error) {
        console.error('âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨:', audioPath, error);
        throw new Error('TTS íŒŒì¼ ìƒì„± ì‹¤íŒ¨');
      }
      
      // URL ìƒì„±
      const audioUrl = `/audio/${filename}`;
      
      // ë³¼ë¥¨ ë°ì´í„° ìƒì„± (ê°„ë‹¨í•œ ë”ë¯¸ ë°ì´í„°, ì‹¤ì œë¡œëŠ” ì˜¤ë””ì˜¤ ë¶„ì„ í•„ìš”)
      const volumes = this.generateVolumeData(cleanText.length);
      
      console.log('ğŸµ TTS ìƒì„± ì™„ë£Œ:', {
        filename,
        audioUrl,
        absolutePath: audioPath,
        fileSize: buffer.length,
        volumesCount: volumes.length
      });

      // 5ë¶„ í›„ ì„ì‹œ íŒŒì¼ ì‚­ì œ ìŠ¤ì¼€ì¤„ë§
      setTimeout(async () => {
        try {
          await fs.unlink(audioPath);
          console.log('ğŸ—‘ï¸  ì„ì‹œ TTS íŒŒì¼ ì‚­ì œ:', filename);
        } catch (error) {
          console.warn('âš ï¸ TTS íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨:', filename, error);
        }
      }, 5 * 60 * 1000); // 5ë¶„

      return { audioUrl, volumes };

    } catch (error) {
      console.error('ğŸš« OpenAI TTS API ì˜¤ë¥˜:', error);
      throw error;
    }
  }

  private generateVolumeData(textLength: number): number[] {
    // í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë³¼ë¥¨ ë°ì´í„° ìƒì„±
    // ì‹¤ì œë¡œëŠ” ì˜¤ë””ì˜¤ ë¶„ì„ì´ í•„ìš”í•˜ì§€ë§Œ, ì„ì‹œë¡œ ê°„ë‹¨í•œ íŒ¨í„´ ìƒì„±
    const duration = Math.max(textLength * 0.1, 2); // ìµœì†Œ 2ì´ˆ
    const frameRate = 60; // 60fps
    const totalFrames = Math.floor(duration * frameRate);
    
    const volumes: number[] = [];
    
    for (let i = 0; i < totalFrames; i++) {
      // ì‚¬ì¸íŒŒ ê¸°ë°˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë³¼ë¥¨ ë³€í™”
      const progress = i / totalFrames;
      const baseVolume = 0.3 + Math.sin(progress * Math.PI * 4) * 0.2;
      const randomVariation = (Math.random() - 0.5) * 0.1;
      const volume = Math.max(0, Math.min(1, baseVolume + randomVariation));
      volumes.push(volume);
    }
    
    return volumes;
  }

  private async handleInterrupt(client: ClientConnection) {
    console.log(`âš ï¸  ëŒ€í™” ì¤‘ë‹¨ ìš”ì²­ (${client.id})`);
    
    this.sendMessage(client, {
      type: 'conversation-interrupted',
      timestamp: Date.now()
    });
  }

  private async handleModelSwitch(client: ClientConnection, modelName: string) {
    if (!modelName) return;

    const model = this.modelConfigs.find(m => m.name === modelName);
    if (!model) {
      this.sendError(client, `ëª¨ë¸ '${modelName}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.`);
      return;
    }

    client.currentModel = modelName;
    client.currentEmotion = 'neutral';

    console.log(`ğŸ”„ ëª¨ë¸ ë³€ê²½ (${client.id}): ${modelName}`);

    this.sendMessage(client, {
      type: 'model-switched',
      model: modelName,
      emotions: this.getAvailableEmotions(modelName),
      timestamp: Date.now()
    });
  }

  private sendMessage(client: ClientConnection, message: any) {
    try {
      if (client.ws.readyState === WebSocket.OPEN) {
        const messageStr = JSON.stringify(message);
        console.log(`ğŸ“¤ ë©”ì‹œì§€ ì „ì†¡ (${client.id}):`, message.type, messageStr.length, 'bytes');
        client.ws.send(messageStr);
      } else {
        console.warn(`âŒ í´ë¼ì´ì–¸íŠ¸ ${client.id} WebSocketì´ ì—´ë ¤ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ìƒíƒœ: ${client.ws.readyState}`);
      }
    } catch (error) {
      console.error(`âŒ ë©”ì‹œì§€ ì „ì†¡ ì˜¤ë¥˜ (${client.id}):`, error);
    }
  }

  private sendError(client: ClientConnection, error: string) {
    this.sendMessage(client, {
      type: 'error',
      message: error,
      timestamp: Date.now()
    });
  }

  private startHeartbeat() {
    setInterval(() => {
      this.wss.clients.forEach((ws) => {
        // ê° í´ë¼ì´ì–¸íŠ¸ì˜ ìƒì¡´ í™•ì¸
        const client = Array.from(this.clients.values()).find(c => c.ws === ws);
        if (client) {
          // ì—°ê²° ì•ˆì •ì„±ì„ ìœ„í•´ íƒ€ì„ì•„ì›ƒ ì¡°ê±´ ì™„í™”
          if (!client.isAlive && client.ws.readyState !== WebSocket.OPEN) {
            console.log(`ğŸ’€ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ (íƒ€ì„ì•„ì›ƒ): ${client.id}`);
            client.ws.terminate();
            this.clients.delete(client.id);
            return;
          }
          
          // pingë§Œ ì „ì†¡í•˜ê³  ì¦‰ì‹œ ì¢…ë£Œí•˜ì§€ ì•ŠìŒ
          if (client.ws.readyState === WebSocket.OPEN) {
            client.isAlive = false;
            client.ws.ping();
          }
        }
      });
    }, 60000); // 60ì´ˆë§ˆë‹¤ ì²´í¬ (ê°„ê²© ì¦ê°€)
  }

  public getStats() {
    return {
      connectedClients: this.clients.size,
      availableModels: this.modelConfigs.length,
      openaiConfigured: !!this.openai,
      uptime: process.uptime()
    };
  }
}
